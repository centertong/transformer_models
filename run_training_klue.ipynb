{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16809,"status":"ok","timestamp":1638250618097,"user":{"displayName":"tongth","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15519044452024696097"},"user_tz":-540},"id":"FPYpyg172Oge","outputId":"2fe83c8d-bb98-4e59-9e58-e93b13dbbbf5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/My Drive/Projects/transformers\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/My Drive/Projects/transformers/"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":133527,"status":"ok","timestamp":1638250751622,"user":{"displayName":"tongth","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15519044452024696097"},"user_tz":-540},"id":"loHk_JId2Ogg","outputId":"dbb25c54-f7ff-4df2-91f9-a76b7d186840"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torch==1.9.0\n","  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |████████████████████████████████| 831.4 MB 2.6 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0) (3.10.0.2)\n","Installing collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.9.0 which is incompatible.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.9.0 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0\n","Collecting transformers\n","  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 14.4 MB/s \n","\u001b[?25hCollecting tokenizers\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 63.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting pyyaml\u003e=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 69.6 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting huggingface-hub\u003c1.0,\u003e=0.1.0\n","  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 9.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 77.5 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers) (3.0.6)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers) (3.6.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (1.24.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2021.10.8)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2.10)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n","Collecting einops\n","  Downloading einops-0.3.2-py3-none-any.whl (25 kB)\n","Installing collected packages: einops\n","Successfully installed einops-0.3.2\n"]}],"source":["!pip install torch==1.9.0\n","!pip install transformers tokenizers\n","!pip install einops\n","# !pip install reformer_pytorch\n","#!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n","# #!export XRT_TPU_CONFIG=\"tpu_worker;0;$TPU_IP_ADDRESS:8470\"\n","\n","# VERSION: str = \"1.9\"\n","\n","# wheel: str = f\"torch_xla-{VERSION}-cp37-cp37m-linux_x86_64.whl\"\n","# base_url: str = \"https://storage.googleapis.com/tpu-pytorch/wheels\"\n","# url: str = f\"{base_url}/{wheel}\"\n","\n","# !pip3 install cloud-tpu-client $url"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1638250751623,"user":{"displayName":"tongth","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15519044452024696097"},"user_tz":-540},"id":"wt7W1fqI2Ogg"},"outputs":[],"source":["#!PYTHONPATH=/content/drive/My\\ Drive/Projects/transformers/ python run/train_klue.py --config configs/model/bert.json --tokenizer vocab/bert2/tokenizer.json --type tc --save_path save/klue_tc/ --epochs 10 --batch_size 24 --name rfa2 --model rfa"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1638250751623,"user":{"displayName":"tongth","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15519044452024696097"},"user_tz":-540},"id":"fxuiwL9hcpkn"},"outputs":[],"source":["pythonpath: str = \"/content/drive/My\\ Drive/Projects/transformers/\"\n","config: str = \"configs/model/rfa.json\"\n","tokenizer: str = \"vocab/bert2/tokenizer.json\"\n","save_path: str = \"save/klue_tc/\"\n","\n","# !PYTHONPATH=$pythonpath python run/train_klue.py --config $config --tokenizer $tokenizer --type tc --save_path $save_path --epochs 5 --batch_size 24 --name rfa"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1638250751623,"user":{"displayName":"tongth","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15519044452024696097"},"user_tz":-540},"id":"ReqNQbhZb06h"},"outputs":[],"source":["pythonpath: str = \"/content/drive/My\\ Drive/Projects/transformers/\"\n","config: str = \"configs/model/lite.json\"\n","tokenizer: str = \"vocab/bert2/tokenizer.json\"\n","save_path: str = \"save/klue_tc/\"\n","\n","# !PYTHONPATH=$pythonpath python run/train_klue.py --config $config --tokenizer $tokenizer --type tc --save_path $save_path --epochs 2 --batch_size 12 --name lite"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"7o6IplS92ipH"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n","Epoch-0 Iterator:  50% 1900/3807 [09:58\u003c09:39,  3.29it/s, 2021-11-30 05:49:42.648919 | Train Loss: 1.9695643186569214 | Steps: 1900]/content/drive/My Drive/Projects/transformers/utils/trainer.py:137: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1)\n","Epoch-0 Iterator: 100% 3807/3807 [20:02\u003c00:00,  3.16it/s, 2021-11-30 05:59:46.675591 | Train Loss: nan | Steps: 3807]\n","Evaluating: 100% 380/380 [01:11\u003c00:00,  5.31it/s]\n","0.08256000713839558\n","Epoch-1 Iterator: 100% 3807/3807 [20:20\u003c00:00,  3.12it/s, 2021-11-30 06:21:18.554181 | Train Loss: nan | Steps: 7614]\n","Evaluating: 100% 380/380 [01:10\u003c00:00,  5.37it/s]\n","0.08256000713839558\n","Epoch-2 Iterator: 100% 3807/3807 [20:39\u003c00:00,  3.07it/s, 2021-11-30 06:43:08.407852 | Train Loss: nan | Steps: 11421]\n","Evaluating: 100% 380/380 [01:10\u003c00:00,  5.37it/s]\n","0.08256000713839558\n"]}],"source":["pythonpath: str = \"/content/drive/My\\ Drive/Projects/transformers/\"\n","config: str = \"configs/model/aft.json\"\n","tokenizer: str = \"vocab/bert2/tokenizer.json\"\n","save_path: str = \"save/klue_tc/\"\n","\n","!PYTHONPATH=$pythonpath python run/train_klue.py --config $config --tokenizer $tokenizer --type tc --save_path $save_path --epochs 3 --batch_size 12 --name aft_base"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"YNDkxLyIg0J6"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"run_training_klue.ipynb","version":""},"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"},"kernelspec":{"display_name":"Python 3.7.12 64-bit","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":0}